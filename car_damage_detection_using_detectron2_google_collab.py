# -*- coding: utf-8 -*-
"""Copy of car_damage_detection_using_detectron2_google_collab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_gQP0Pnhl6gNeEE3Iht9LqnpogUhFVzf

# Download Kaggle Dataset
"""

! pip install -q kaggle

# upload kaggle API Token
from google.colab import files
files.upload()

# Make directory named kaggle and copy kaggle.json file there.
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle

# Change the permissions of the file.
! chmod 600 ~/.kaggle/kaggle.json
# check access to kaggle
! kaggle datasets list

# Download the dataset
! kaggle datasets download -d lplenka/coco-car-damage-detection-dataset

# create dataset folder
! mkdir car_damage_datasets

# unzip and move to dataset folder
! unzip coco-car-damage-detection-dataset.zip -d car_damage_datasets

"""# Install COCO"""

!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'

"""# Import Libraries"""

# Commented out IPython magic to ensure Python compatibility.
from pycocotools.coco import COCO
import numpy as np
import skimage.io as io
import random
import os
import cv2
from tensorflow.keras.preprocessing.image import ImageDataGenerator

### For visualizing the outputs ###
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
# %matplotlib inline

"""# Dataset Exploration"""

dataDir='/content/car_damage_datasets'
dataTrain ='train'
dataVal='val'
dataTest='test'
annFileVal='{}/{}/COCO_{}_annos.json'.format(dataDir,dataVal,dataVal)
annFileTrain='{}/{}/COCO_{}_annos.json'.format(dataDir,dataTrain,dataTrain)

# Initialize the COCO api for instance annotations
coco=COCO(annFileVal)

# Load the categories in a variable
catIDs = coco.getCatIds()
cats = coco.loadCats(catIDs)

print(cats)

imgIds = coco.getImgIds(catIds=catIDs)
print("Number of images containing all the  classes:", len(imgIds))

# load and display a random image
img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]
print(img)
I = io.imread('{}/{}/{}'.format(dataDir,dataVal,img['file_name']))/255.0

plt.axis('off')
plt.imshow(I)
plt.show()

# Load and display instance annotations
plt.imshow(I)
plt.axis('off')
annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIDs, iscrowd=None)
anns = coco.loadAnns(annIds)
coco.showAnns(anns)

"""# Install Detectron2"""

!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'

import torch, torchvision, detectron2
!nvcc --version
TORCH_VERSION = ".".join(torch.__version__.split(".")[:2])
CUDA_VERSION = torch.__version__.split("+")[-1]
print("torch: ", TORCH_VERSION, "; cuda: ", CUDA_VERSION)
print("detectron2:", detectron2.__version__)

print(torch.__version__, torch.cuda.is_available())

# Some basic setup:
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import os, json, cv2, random
# from google.colab.patches import cv2_imshow

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog, DatasetMapper, build_detection_train_loader
import detectron2.data.transforms as T
from detectron2.utils.visualizer import ColorMode

from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
from detectron2.engine import DefaultTrainer

"""# Register COCO dataset"""

from detectron2.data.datasets import register_coco_instances
try:
    register_coco_instances("dataset_train", {}, annFileTrain, "{}/{}".format(dataDir,dataTrain))
    register_coco_instances("dataset_val", {}, annFileVal, "{}/{}".format(dataDir, dataVal))
except:
    print('Dataset is already registered!')
    pass

dataset_dicts = DatasetCatalog.get("dataset_train")
metadata_dicts = MetadataCatalog.get("dataset_train")

"""Verify that the dataset is in correct format, let's visualize the annotation on random sample in training set"""

for d in random.sample(dataset_dicts, 3):
    img = cv2.imread(d["file_name"])
    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata_dicts, scale=0.5)
    out = visualizer.draw_dataset_dict(d)
    plt.axis('off')
    plt.imshow(out.get_image()[:, :, ::-1])

"""# Training

## Create evaluator and augmentation
"""

# create trainer with evaluation and augmentation
# https://github.com/facebookresearch/detectron2/blob/main/tools/train_net.py
class Trainer(DefaultTrainer): # inherit from default trainer
    @classmethod
    def build_evaluator(cls, cfg, dataset_name, output_folder=None):
        if output_folder is None:
            output_folder = os.path.join(cfg.OUTPUT_DIR, "evaluator")
        return COCOEvaluator(dataset_name, ("bbox", "segm"), output_folder)
    @classmethod
    def build_train_loader(cls, cfg):
        augs = [
            T.ResizeShortestEdge(cfg.INPUT.MIN_SIZE_TRAIN, cfg.INPUT.MAX_SIZE_TRAIN, cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING),
            T.RandomFlip(prob=0.5, horizontal=True, vertical=False),
            T.RandomRotation([-90, 90]),
            T.RandomLighting(0.5)
        ]
        mapper = DatasetMapper(cfg, is_train=True, augmentations=augs)
        return build_detection_train_loader(cfg, mapper=mapper)

# list of configs: https://github.com/facebookresearch/detectron2/blob/main/detectron2/config/defaults.py

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("dataset_train",)
cfg.DATASETS.TEST = ("dataset_val",)
cfg.DATALOADER.NUM_WORKERS = 2 # 2 is enough
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")  # Let training initialize from model zoo
cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real "batch size" commonly known to deep learning people
cfg.SOLVER.BASE_LR = 0.001 #0.0005 #0.00025  # pick a good LR
cfg.SOLVER.MAX_ITER = 800    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset
cfg.SOLVER.STEPS = []      # do not decay learning rate
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The "RoIHead batch size". 128 is faster, and good enough for this toy dataset (default: 512)
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (damage). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)
# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.
cfg.TEST.EVAL_PERIOD = 200 # eval every 200 iter

# Clear any logs from previous runs
import shutil
try:
  shutil.rmtree(cfg.OUTPUT_DIR)
except:
  print('no folder found, pass')

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = Trainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

"""# Training Graph"""

# Commented out IPython magic to ensure Python compatibility.
# Look at training curves in tensorboard:
# %load_ext tensorboard
# %tensorboard --logdir output

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Results from the evaluation
results = {
    'bbox': {
        'AP': 6.515842573054785,
        'AP50': 18.32064785759742,
        'AP75': 0.10733992653923778,
        'APs': 0.0,
        'APm': 9.438998792096454,
        'APl': 7.127512650380968
    },
    'segm': {
        'AP': 14.594154809933087,
        'AP50': 22.3663125172583,
        'AP75': 17.58868029660109,
        'APs': 0.0,
        'APm': 13.244277511763936,
        'APl': 22.277055245571887
    }
}

# Create a DataFrame
df = pd.DataFrame(data=results)

# Plot the metrics
sns.set(style="whitegrid")
plt.figure(figsize=(12, 6))
df.T.plot(kind='bar', ax=plt.gca())
plt.title('Metric Values for Different Tasks')
plt.xlabel('Task')
plt.ylabel('Value')
plt.legend(title='Metric', bbox_to_anchor=(1.05, 1), loc='upper left')

plt.show()

"""# Evaluation"""

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")  # path to the model we just trained
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold
predictor = DefaultPredictor(cfg)

evaluator = COCOEvaluator("dataset_val", output_dir="./output")
val_loader = build_detection_test_loader(cfg, "dataset_val")
print(inference_on_dataset(predictor.model, val_loader, evaluator))
# another equivalent way to evaluate the model is to use `trainer.test`

"""# Inference Val"""

def inference(listImg):
    for img in listImg:
        im = io.imread(img)
        outputs = predictor(im)
        v = Visualizer(im[:, :, ::-1],
                       metadata=val_metadata_dicts,
                       scale=0.5,
    #                    instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models
        )
        out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
        plt.figure(figsize=(50,50))
        plt.subplot(1, 2, 1)
        plt.axis('off')
        plt.grid(False)
        plt.imshow(out.get_image()[:, :, ::-1])
        masks = outputs['instances'].pred_masks.cpu().numpy().astype('uint8')
        total_area = outputs['instances'].pred_boxes.area().sum()
        plt.text(20, 40, 'Number of Damaged: {}\n Damaged Area: {} px^2'.format(len(masks), total_area), fontsize = 40, color = 'white', bbox = dict(facecolor = 'red', alpha = 0.5))
        plt.subplot(1, 2, 2)
        plt.axis('off')
        plt.imshow(im)
        plt.show()

val_dataset_dicts = DatasetCatalog.get("dataset_val")
val_metadata_dicts = MetadataCatalog.get("dataset_val")

imgVal = [d['file_name'] for d in random.sample(val_dataset_dicts, 6)]

inference(imgVal)

"""# Inference Test"""

import glob

testImg = glob.glob('/{}/{}/*.jpg'.format(dataDir,dataTest))
print(len(testImg),'items, sample:', testImg[0])

inference(testImg)

from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader

# Load the trained model
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
predictor = DefaultPredictor(cfg)

# Create an evaluator
evaluator = COCOEvaluator("dataset_val", output_dir="./output")

# Build a test data loader for the validation dataset
val_loader = build_detection_test_loader(cfg, "dataset_val")

# Perform inference and evaluation
results = inference_on_dataset(predictor.model, val_loader, evaluator)
print(results)